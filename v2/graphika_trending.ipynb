{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nodes_data(hits_df):\n",
    "    groupname_values = hits_df.apply(groupname_lookup,axis = 1,result_type = 'reduce')\n",
    "    hits_df.insert(loc = hits_df.shape[1]-1,column = 'group_name', value = groupname_values)\n",
    "\n",
    "    clustername_values = hits_df.apply(clustername_lookup,axis = 1,result_type = 'reduce')\n",
    "    hits_df.insert(loc = hits_df.shape[1]-1,column = 'cluster_name', value = clustername_values)\n",
    "\n",
    "    nodename_values = hits_df.apply(nodename_lookup,axis = 1,result_type = 'reduce')\n",
    "    hits_df.insert(loc = hits_df.shape[1]-1,column = 'node_name', value = nodename_values)\n",
    "    \n",
    "    return hits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_writer(table,map_id,limit = 10,dayrange = 30,platform = 'twitter'):\n",
    "    if limit == False:\n",
    "        limit = ''\n",
    "    else:\n",
    "        limit = 'LIMIT ' + str(limit)\n",
    "    nowtime = datetime.now().strftime('%Y-%m-%d %H:%M:%S') #np.datetime64('now')\n",
    "    pasttime = (datetime.now() - timedelta(days = dayrange)).strftime('%Y-%m-%d %H:%M:%S') #nowtime - np.timedelta64(dayrange,'D')\n",
    "\n",
    "    q = \"SELECT * FROM \\\n",
    "    \\\n",
    "    ( \\\n",
    "    SELECT \\\n",
    "    * \\\n",
    "    FROM \\\n",
    "    hits_{5}_{0} \\\n",
    "    JOIN \\\n",
    "    map_nodes on map_nodes.node_id = hits_{5}_{0}.node_id \\\n",
    "    ) s \\\n",
    "    WHERE \\\n",
    "    s.map_id = '{1}' \\\n",
    "    AND \\\n",
    "    s.hit_time BETWEEN '{3}'::TIMESTAMP AND '{4}'::TIMESTAMP \\\n",
    "    {2};;\".format(table,map_id,limit,pasttime,nowtime,platform)\n",
    "    return q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hits(hit_type, hit_value, how_many = 10,days = 30,platform = 'twitter'):\n",
    "    query = query_writer(hit_type,hit_value,how_many,days,platform)\n",
    "    \n",
    "    r = cur.execute(query)\n",
    "    hits = cur.fetchall()\n",
    "    hits_df = pd.DataFrame(hits, columns=[\"id\",\"hit_value\", \"node_id\", \"message_id\",\"hit_time\",\"params\",\"id_2\",\"node_id2\",\"map_id\",\"cluster_id\"])\n",
    "    \n",
    "    hits_df[\"node_id\"] = hits_df[\"node_id\"].astype(\"str\")\n",
    "    hits_df[\"message_id\"] = hits_df[\"message_id\"].astype(\"str\")\n",
    "    hits_df[\"hit_type\"] = hit_type\n",
    "    hits_df.drop_duplicates('id',inplace = True)\n",
    "    hits_df.drop(columns = ['node_id2','id_2','id','params'],inplace = True)\n",
    "\n",
    "    return hits_df.set_index(['hit_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_trends(map_id,hit_type = 'hashtags',pltfrm = 'twitter',limit = 1000, days = 100):\n",
    "    return get_hits(hit_type,map_id,limit,days,pltfrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_group_count(map_id):\n",
    "    url = 'https://api.graphika.com/maps/{}/groups'.format(map_id)\n",
    "    r = re.get(url,auth = (username,pswd))\n",
    "    result = r.json()\n",
    "    return result[-1]['group_no'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_live_map_ids():\n",
    "    url = 'https://api.graphika.com/maps'\n",
    "    \n",
    "    r = re.get(url,auth = (username,pswd))\n",
    "    result = r.json()\n",
    "    live_map_ids = []\n",
    "    live_map_names = []\n",
    "    for map_dict in result:\n",
    "        if map_dict['is_live'] == True:\n",
    "            live_map_ids.append(map_dict['id'])\n",
    "            live_map_names.append(map_dict['name'])\n",
    "    return live_map_ids,live_map_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphika_trending(debug = False,days = 7):\n",
    "    days = int(input('>> Enter how many days of trending hits you would like to pull: '))\n",
    "#     platform = input('>> Enter the platform you would like to explore (twitter,youtube): ')\n",
    "    platform = 'twitter'\n",
    "    hit_type = input('>> Enter the type of hit you would like to explore (hashtags,urls,media): ')\n",
    "    live_hashtags = []\n",
    "    top_hits = pd.DataFrame()\n",
    "    id_list,name_list = get_live_map_ids()\n",
    "    if debug:\n",
    "        id_list = id_list[:3]\n",
    "        name_list = name_list[:3]\n",
    "    print('...Looking at live maps:')\n",
    "    print('\\n'.join(name_list))\n",
    "    for map_id in id_list:\n",
    "        top_hits = top_hits.append(get_top_trends(map_id,hit_type,platform,10000,days))\n",
    "\n",
    "    if not debug:\n",
    "        print('...Computing map counts')\n",
    "        top_hits = top_hits.merge(get_node_map_counts(top_hits),how = 'left',left_on = 'node_id',right_index = True)\n",
    "    print('...Done!')\n",
    "    if input('>> Do you want to save these results to a CSV? (y/n) \\n') == 'y':\n",
    "            print_csv(top_hits)\n",
    "    return top_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_map_counts(df):\n",
    "    temp_pivot = pd.pivot_table(df, values='map_id', index='node_id', aggfunc=pd.Series.nunique)\n",
    "    return temp_pivot.sort_values('map_id',ascending = False).rename(columns = {'map_id':'map_id_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_x_trends(top_tags,how_many = 30):\n",
    "    print('...Getting a summary of top {} hits'.format(how_many))\n",
    "#     how_many = input('>> Enter how many of the top hashtags you would like to view: ')\n",
    "    top_x = []\n",
    "    for tag in pd.DataFrame(top_tags.index.value_counts().head(how_many)).index.tolist():\n",
    "        top_x.append({'hit_value':tag,\\\n",
    "                      'hit_count': top_tags[top_tags.index == tag].shape[0], \\\n",
    "                      'hit_share': round(100*top_tags[top_tags.index == tag].shape[0]/top_tags.shape[0],2), \\\n",
    "                      'tweet_count':top_tags.groupby('hit_value').get_group(tag).message_id.nunique(), \\\n",
    "                      'tweet_share':round(100*top_tags.groupby('hit_value').get_group(tag).message_id.nunique()/top_tags.message_id.nunique(),2), \\\n",
    "                      'map_count':top_tags.groupby('hit_value').get_group(tag).map_id.nunique(), \\\n",
    "                      'node_count':top_tags.groupby('hit_value').get_group(tag).node_id.nunique(),\n",
    "                      'node_share':round(100*top_tags.groupby('hit_value').get_group(tag).node_id.nunique()/top_tags.node_id.nunique(),2) \\\n",
    "                     })\n",
    "    \n",
    "    print('...Done!')\n",
    "    return pd.DataFrame(top_x).set_index('hit_value')\n",
    "    # top25 = pd.DataFrame(top_tags.index.value_counts().head(50)).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_hit(sum_df,res_df):\n",
    "    hit = input('>> Enter a hit to get its summary: ')\n",
    "    print('--------------------')\n",
    "    print('{} SUMMARY'.format(hit))\n",
    "    search = sum_df[sum_df.index == hit]\n",
    "    if search.empty:\n",
    "        print('**This is not a top hit**')\n",
    "    else:\n",
    "        print('{} appeared across {} live maps, and accounted for:\\n-->{}% of all hits\\n-->{}% of all posts\\n-->and was shared by {}% of all accounts\\n'.format( \\\n",
    "            hit,search.map_count.values[0],search.hit_share.values[0],search.tweet_share.values[0],search.node_share.values[0]))\n",
    "        print('The maps {} appears in are:'.format(hit))\n",
    "        for x in res_df[res_df.index == hit].map_id.value_counts().index.tolist():\n",
    "            print('-->{} with \\n---->{} hit(s)'.format(get_map_name(x),res_df[res_df.index == hit].map_id.value_counts()[x]))\n",
    "        print()\n",
    "\n",
    "    search = res_df[res_df.index == hit]\n",
    "    \n",
    "    if search.empty:\n",
    "        print('**Hit not found**')\n",
    "        return\n",
    "    else:\n",
    "        id_list = search[search.map_id_count > 0][['node_id','map_id']].values.tolist()\n",
    "        id_set = set(map(tuple,id_list))\n",
    "        print('...Getting the metadata of accounts that appeared across multiple maps for this hit:')\n",
    "        influencer_df = pd.DataFrame()\n",
    "        influencer_col = []\n",
    "        maps = []\n",
    "        for ids in id_set:\n",
    "            maps.append(ids[1])\n",
    "#             print('MAP: {}'.format(get_map_name(ids[1])))\n",
    "            url = 'https://api.graphika.com/nodes/{}'.format(ids[0])\n",
    "#             print(url)\n",
    "            r = re.get(url,auth = (username,pswd))\n",
    "            inf = r.json()['influencers']\n",
    "            if len(inf) > 0:\n",
    "                influencer_col.append(True)\n",
    "#                 print('This account is an influencer in the following maps: {}'.format(inf))\n",
    "            else:\n",
    "                influencer_col.append(False)\n",
    "#                 print('This account is not an influencer')\n",
    "            influencer_df = influencer_df.append(get_node_metadata(ids[0],ids[1]).set_index('name'))\n",
    "        influencer_df['influencer'] = influencer_col\n",
    "        influencer_df['map_id'] = maps\n",
    "        influencer_df = influencer_df.rename(columns = {'node_source_id':'node_id'})\n",
    "        influencer_df = fill_nodes_data(influencer_df)\n",
    "        return influencer_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
